import streamlit as st
from PIL import Image, ImageEnhance, ImageFilter
import pytesseract
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from datetime import datetime
import time
import json
import base64
import os
import re
from io import BytesIO

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Samsung AI Text Recognition",
    page_icon="ğŸ“±",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì‚¼ì„± ìŠ¤íƒ€ì¼ CSS
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&display=swap');

/* ì „ì²´ ìŠ¤íƒ€ì¼ */
html, body, [class*="css"] {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif !important;
    background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
}

/* í—¤ë” ìŠ¤íƒ€ì¼ */
.main-header {
    background: linear-gradient(135deg, #1428a0 0%, #1e40af 50%, #3b82f6 100%);
    color: white;
    padding: 4rem 2rem 3rem 2rem;
    border-radius: 0 0 40px 40px;
    margin: -1rem -1rem 3rem -1rem;
    text-align: center;
    box-shadow: 0 20px 60px rgba(20, 40, 160, 0.3);
    position: relative;
    overflow: hidden;
}

.main-header::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><defs><pattern id="grid" width="10" height="10" patternUnits="userSpaceOnUse"><path d="M 10 0 L 0 0 0 10" fill="none" stroke="rgba(255,255,255,0.1)" stroke-width="0.5"/></pattern></defs><rect width="100" height="100" fill="url(%23grid)"/></svg>');
    opacity: 0.3;
}

.main-header h1 {
    font-size: 3.5rem;
    font-weight: 900;
    margin-bottom: 1rem;
    background: linear-gradient(135deg, #ffffff 0%, #e0e7ff 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    position: relative;
    z-index: 1;
}

.main-header p {
    font-size: 1.4rem;
    font-weight: 400;
    opacity: 0.9;
    margin-bottom: 0;
    position: relative;
    z-index: 1;
}

/* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
.feature-card {
    background: white;
    border-radius: 24px;
    padding: 2.5rem;
    margin-bottom: 2rem;
    box-shadow: 0 10px 40px rgba(0,0,0,0.08);
    border: 1px solid rgba(255,255,255,0.2);
    transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
    position: relative;
    overflow: hidden;
}

.feature-card::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 4px;
    background: linear-gradient(135deg, #1428a0 0%, #3b82f6 100%);
}

.feature-card:hover {
    transform: translateY(-8px);
    box-shadow: 0 20px 60px rgba(0,0,0,0.15);
}

/* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
.samsung-btn {
    background: linear-gradient(135deg, #1428a0 0%, #3b82f6 100%);
    color: white !important;
    border: none;
    border-radius: 16px;
    padding: 1rem 2rem;
    font-weight: 600;
    font-size: 1rem;
    box-shadow: 0 8px 25px rgba(20, 40, 160, 0.3);
    transition: all 0.3s ease;
    cursor: pointer;
}

.samsung-btn:hover {
    transform: translateY(-2px);
    box-shadow: 0 12px 35px rgba(20, 40, 160, 0.4);
    background: linear-gradient(135deg, #1e40af 0%, #60a5fa 100%);
}

/* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ */
.sidebar .sidebar-content {
    background: linear-gradient(180deg, #f8fafc 0%, #e2e8f0 100%);
    border-right: 1px solid rgba(0,0,0,0.1);
}

/* íƒ­ ìŠ¤íƒ€ì¼ */
.stTabs [data-baseweb="tab-list"] {
    justify-content: center;
    gap: 0.5rem;
    background: white;
    border-radius: 20px;
    padding: 0.5rem;
    box-shadow: 0 4px 20px rgba(0,0,0,0.08);
    margin-bottom: 2rem;
}

.stTabs [data-baseweb="tab"] {
    border-radius: 16px;
    font-weight: 600;
    transition: all 0.3s ease;
    padding: 0.75rem 1.5rem;
}

.stTabs [aria-selected="true"] {
    background: linear-gradient(135deg, #1428a0 0%, #3b82f6 100%);
    color: white !important;
    box-shadow: 0 4px 15px rgba(20, 40, 160, 0.3);
}

/* ë©”íŠ¸ë¦­ ì¹´ë“œ */
.metric-card {
    background: linear-gradient(135deg, #1428a0 0%, #3b82f6 100%);
    color: white;
    border-radius: 20px;
    padding: 2rem;
    text-align: center;
    box-shadow: 0 8px 30px rgba(20, 40, 160, 0.2);
    margin-bottom: 1rem;
    position: relative;
    overflow: hidden;
}

.metric-card::before {
    content: '';
    position: absolute;
    top: -50%;
    left: -50%;
    width: 200%;
    height: 200%;
    background: linear-gradient(45deg, transparent, rgba(255,255,255,0.1), transparent);
    transform: rotate(45deg);
    animation: shimmer 3s infinite;
}

@keyframes shimmer {
    0% { transform: translateX(-100%) translateY(-100%) rotate(45deg); }
    100% { transform: translateX(100%) translateY(100%) rotate(45deg); }
}

/* ì• ë‹ˆë©”ì´ì…˜ */
@keyframes fadeInUp {
    from {
        opacity: 0;
        transform: translateY(30px);
    }
    to {
        opacity: 1;
        transform: translateY(0);
    }
}

@keyframes slideInLeft {
    from {
        opacity: 0;
        transform: translateX(-50px);
    }
    to {
        opacity: 1;
        transform: translateX(0);
    }
}

@keyframes slideInRight {
    from {
        opacity: 0;
        transform: translateX(50px);
    }
    to {
        opacity: 1;
        transform: translateX(0);
    }
}

@keyframes zoomIn {
    from {
        opacity: 0;
        transform: scale(0.8);
    }
    to {
        opacity: 1;
        transform: scale(1);
    }
}

.fade-in-up {
    animation: fadeInUp 0.6s ease-out;
}

.slide-in-left {
    animation: slideInLeft 0.8s ease-out;
}

.slide-in-right {
    animation: slideInRight 0.8s ease-out;
}

.zoom-in {
    animation: zoomIn 0.5s ease-out;
}

/* í˜¸ë²„ íš¨ê³¼ */
.hover-lift {
    transition: transform 0.3s ease, box-shadow 0.3s ease;
}

.hover-lift:hover {
    transform: translateY(-5px);
    box-shadow: 0 15px 40px rgba(0,0,0,0.15);
}

/* ê·¸ë¼ë°ì´ì…˜ í…ìŠ¤íŠ¸ */
.gradient-text {
    background: linear-gradient(135deg, #1428a0 0%, #3b82f6 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    font-weight: 700;
}

/* ê²€ìƒ‰ ê²°ê³¼ í•˜ì´ë¼ì´íŠ¸ */
.search-highlight {
    background: linear-gradient(135deg, #1428a0 0%, #3b82f6 100%);
    color: white;
    padding: 0.2rem 0.5rem;
    border-radius: 4px;
    font-weight: 600;
}

/* ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ */
.loading-spinner {
    display: inline-block;
    width: 20px;
    height: 20px;
    border: 3px solid rgba(255,255,255,.3);
    border-radius: 50%;
    border-top-color: #fff;
    animation: spin 1s ease-in-out infinite;
}

@keyframes spin {
    to { transform: rotate(360deg); }
}

/* ë°˜ì‘í˜• ë””ìì¸ */
@media (max-width: 768px) {
    .main-header h1 {
        font-size: 2.5rem;
    }
    
    .feature-card {
        padding: 1.5rem;
    }
}

/* ìŠ¤í¬ë¡¤ë°” ìŠ¤íƒ€ì¼ */
::-webkit-scrollbar {
    width: 8px;
}

::-webkit-scrollbar-track {
    background: #f1f5f9;
}

::-webkit-scrollbar-thumb {
    background: linear-gradient(135deg, #1428a0 0%, #3b82f6 100%);
    border-radius: 4px;
}

::-webkit-scrollbar-thumb:hover {
    background: linear-gradient(135deg, #1e40af 0%, #60a5fa 100%);
}

/* ì´ë¯¸ì§€ ì—…ë¡œë“œ ì˜ì—­ */
.upload-area {
    border: 3px dashed #3b82f6;
    border-radius: 20px;
    padding: 3rem;
    text-align: center;
    background: linear-gradient(135deg, rgba(59, 130, 246, 0.05) 0%, rgba(20, 40, 160, 0.05) 100%);
    transition: all 0.3s ease;
}

.upload-area:hover {
    border-color: #1428a0;
    background: linear-gradient(135deg, rgba(59, 130, 246, 0.1) 0%, rgba(20, 40, 160, 0.1) 100%);
}

/* ê²°ê³¼ ì¹´ë“œ */
.result-card {
    background: white;
    border-radius: 20px;
    padding: 2rem;
    margin: 1rem 0;
    box-shadow: 0 8px 30px rgba(0,0,0,0.1);
    border-left: 5px solid #3b82f6;
}

/* ì§„í–‰ë¥  ë°” */
.progress-container {
    background: #e2e8f0;
    border-radius: 10px;
    padding: 0.5rem;
    margin: 1rem 0;
}

.progress-bar {
    background: linear-gradient(135deg, #1428a0 0%, #3b82f6 100%);
    height: 8px;
    border-radius: 5px;
    transition: width 0.3s ease;
}

/* ê³ ê¸‰ ê¸°ëŠ¥ ì¹´ë“œ */
.advanced-feature {
    background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
    border-radius: 16px;
    padding: 1.5rem;
    margin: 1rem 0;
    border: 1px solid rgba(59, 130, 246, 0.2);
}

/* ì„±ê³µ/ì˜¤ë¥˜ ë©”ì‹œì§€ */
.success-message {
    background: linear-gradient(135deg, #10b981 0%, #059669 100%);
    color: white;
    padding: 1rem;
    border-radius: 12px;
    margin: 1rem 0;
}

.error-message {
    background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
    color: white;
    padding: 1rem;
    border-radius: 12px;
    margin: 1rem 0;
}

.warning-message {
    background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
    color: white;
    padding: 1rem;
    border-radius: 12px;
    margin: 1rem 0;
}
</style>

<div class="main-header">
    <h1>ğŸ“± Samsung AI Text Recognition</h1>
    <p>Advanced OCR Technology with AI-Powered Analysis & Insights</p>
</div>
""", unsafe_allow_html=True)

# OCR ì–¸ì–´ ì½”ë“œ ë§¤í•‘ í™•ì¥
LANG_CODE_MAP = {
    "í•œêµ­ì–´": "kor",
    "ì˜ì–´": "eng",
    "ì¼ë³¸ì–´": "jpn",
    "ì¤‘êµ­ì–´ ê°„ì²´": "chi_sim",
    "ì¤‘êµ­ì–´ ë²ˆì²´": "chi_tra",
    "í”„ë‘ìŠ¤ì–´": "fra",
    "ë…ì¼ì–´": "deu",
    "ìŠ¤í˜ì¸ì–´": "spa",
    "ì´íƒˆë¦¬ì•„ì–´": "ita",
    "í¬ë¥´íˆ¬ê°ˆì–´": "por",
    "ëŸ¬ì‹œì•„ì–´": "rus",
    "ì•„ëì–´": "ara",
    "íŒë””ì–´": "hin",
    "íƒœêµ­ì–´": "tha",
    "ë² íŠ¸ë‚¨ì–´": "vie"
}

# AI ëª¨ë¸ ì„ íƒ
AI_MODELS = {
    "Claude Sonnet 4": "claude-sonnet-4-20250514",
    "Claude Haiku": "claude-3-haiku-20240307",
    "GPT-4": "gpt-4",
    "GPT-3.5": "gpt-3.5-turbo"
}

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(image, enhancement_level=1.2):
    """ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ì „ì²˜ë¦¬"""
    try:
        img = Image.open(image).convert("RGB")
        
        # ë°ê¸° ë° ëŒ€ë¹„ í–¥ìƒ
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(enhancement_level)
        
        enhancer = ImageEnhance.Brightness(img)
        img = enhancer.enhance(enhancement_level)
        
        # ì„ ëª…ë„ í–¥ìƒ
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(1.5)
        
        return img
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# ê³ ê¸‰ OCR í•¨ìˆ˜
def advanced_ocr_extraction(image, lang_code, enhancement_level=1.2):
    """ê³ ê¸‰ OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        processed_img = preprocess_image(image, enhancement_level)
        if processed_img is None:
            return "ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨"
        
        # Tesseract OCR ì‹¤í–‰
        text = pytesseract.image_to_string(processed_img, lang=lang_code)
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    except Exception as e:
        return f"OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# AI ìš”ì•½ í•¨ìˆ˜ (ëª¨ì˜)
def ai_summarize_text(text, model_name="Claude Sonnet 4"):
    """AI í…ìŠ¤íŠ¸ ìš”ì•½ (ì‹¤ì œ API í‚¤ê°€ ì—†ì„ ë•Œ ëª¨ì˜ ì‘ë‹µ)"""
    try:
        if len(text) > 100:
            # ê°„ë‹¨í•œ ìš”ì•½ ë¡œì§
            sentences = text.split('.')
            if len(sentences) > 3:
                summary = f"[{model_name} ìš”ì•½] {' '.join(sentences[:3])}... (ì „ì²´ {len(text)}ì ì¤‘ í•µì‹¬ ë‚´ìš© ì¶”ì¶œ)"
            else:
                summary = f"[{model_name} ìš”ì•½] {text[:200]}... (ì „ì²´ {len(text)}ì)"
        else:
            summary = f"[{model_name} ìš”ì•½] {text}"
        
        return summary
    except Exception as e:
        return f"AI ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# í…ìŠ¤íŠ¸ ë¶„ì„ í•¨ìˆ˜
def analyze_text(text):
    """í…ìŠ¤íŠ¸ ë¶„ì„ ë° í†µê³„"""
    if not text:
        return {}
    
    try:
        # ê¸°ë³¸ í†µê³„
        words = text.split()
        sentences = [s.strip() for s in text.split('.') if s.strip()]
        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
        
        # ì–¸ì–´ ê°ì§€ (ê°„ë‹¨í•œ ë°©ì‹)
        korean_chars = sum(1 for char in text if '\u3131' <= char <= '\u318e' or '\uac00' <= char <= '\ud7af')
        english_chars = sum(1 for char in text if char.isascii() and char.isalpha())
        
        if korean_chars > english_chars:
            detected_lang = "í•œêµ­ì–´"
        elif english_chars > korean_chars:
            detected_lang = "ì˜ì–´"
        else:
            detected_lang = "í˜¼í•©"
        
        # ì¶”ê°€ ë¶„ì„
        avg_word_length = np.mean([len(word) for word in words]) if words else 0
        unique_words = len(set(words))
        
        # í…ìŠ¤íŠ¸ ë³µì¡ë„ ì ìˆ˜
        complexity_score = min(100, (avg_word_length * 10 + unique_words / len(words) * 50) if words else 0)
        
        return {
            'char_count': len(text),
            'word_count': len(words),
            'sentence_count': len(sentences),
            'paragraph_count': len(paragraphs),
            'detected_language': detected_lang,
            'avg_word_length': round(avg_word_length, 2),
            'unique_words': unique_words,
            'complexity_score': round(complexity_score, 1),
            'reading_time_minutes': round(len(words) / 200, 1)  # í‰ê·  ì½ê¸° ì†ë„ 200ë‹¨ì–´/ë¶„
        }
    except Exception as e:
        st.error(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return {}

# ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜
def create_text_analysis_charts(analysis_data):
    """í…ìŠ¤íŠ¸ ë¶„ì„ ì°¨íŠ¸ ìƒì„±"""
    if not analysis_data:
        return None, None, None, None
    
    try:
        # 1. ê¸°ë³¸ í†µê³„ ì°¨íŠ¸
        stats_data = {
            'í•­ëª©': ['ë¬¸ì ìˆ˜', 'ë‹¨ì–´ ìˆ˜', 'ë¬¸ì¥ ìˆ˜', 'ë‹¨ë½ ìˆ˜'],
            'ìˆ˜ì¹˜': [
                analysis_data['char_count'],
                analysis_data['word_count'],
                analysis_data['sentence_count'],
                analysis_data['paragraph_count']
            ]
        }
        
        fig1 = px.bar(
            x=stats_data['í•­ëª©'],
            y=stats_data['ìˆ˜ì¹˜'],
            title="ğŸ“Š í…ìŠ¤íŠ¸ ê¸°ë³¸ í†µê³„",
            color=stats_data['ìˆ˜ì¹˜'],
            color_continuous_scale='Blues'
        )
        fig1.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font=dict(family="Inter", size=12),
            height=400
        )
        
        # 2. ì–¸ì–´ ë¶„í¬ íŒŒì´ ì°¨íŠ¸
        lang_data = pd.DataFrame({
            'ì–¸ì–´': [analysis_data['detected_language']],
            'ë¹„ìœ¨': [100]
        })
        
        fig2 = px.pie(
            lang_data,
            values='ë¹„ìœ¨',
            names='ì–¸ì–´',
            title=f"ğŸŒ ê°ì§€ëœ ì–¸ì–´: {analysis_data['detected_language']}",
            color_discrete_sequence=['#3b82f6']
        )
        fig2.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font=dict(family="Inter", size=12),
            height=400
        )
        
        # 3. í…ìŠ¤íŠ¸ ë³µì¡ë„ ì§€í‘œ
        complexity_data = {
            'ì§€í‘œ': ['í‰ê·  ë‹¨ì–´ ê¸¸ì´', 'ê³ ìœ  ë‹¨ì–´ ìˆ˜', 'ë³µì¡ë„ ì ìˆ˜'],
            'ê°’': [
                analysis_data['avg_word_length'],
                analysis_data['unique_words'],
                analysis_data['complexity_score']
            ]
        }
        
        fig3 = px.bar(
            x=complexity_data['ì§€í‘œ'],
            y=complexity_data['ê°’'],
            title="ğŸ“ˆ í…ìŠ¤íŠ¸ ë³µì¡ë„ ë¶„ì„",
            color=complexity_data['ê°’'],
            color_continuous_scale='Viridis'
        )
        fig3.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font=dict(family="Inter", size=12),
            height=400
        )
        
        # 4. ì½ê¸° ì‹œê°„ ë° íš¨ìœ¨ì„±
        reading_data = {
            'ì§€í‘œ': ['ì˜ˆìƒ ì½ê¸° ì‹œê°„ (ë¶„)', 'ë‹¨ì–´ë‹¹ í‰ê·  ë¬¸ì'],
            'ê°’': [
                analysis_data['reading_time_minutes'],
                round(analysis_data['char_count'] / max(analysis_data['word_count'], 1), 2)
            ]
        }
        
        fig4 = px.bar(
            x=reading_data['ì§€í‘œ'],
            y=reading_data['ê°’'],
            title="â±ï¸ ì½ê¸° íš¨ìœ¨ì„± ë¶„ì„",
            color=reading_data['ê°’'],
            color_continuous_scale='Plasma'
        )
        fig4.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font=dict(family="Inter", size=12),
            height=400
        )
        
        return fig1, fig2, fig3, fig4
    except Exception as e:
        st.error(f"ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return None, None, None, None

# ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
def batch_process_images(uploaded_files, lang_code, enhancement_level=1.2):
    """ì—¬ëŸ¬ ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬"""
    results = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, file in enumerate(uploaded_files):
        status_text.text(f"ì²˜ë¦¬ ì¤‘: {file.name} ({i+1}/{len(uploaded_files)})")
        
        try:
            text = advanced_ocr_extraction(file, lang_code, enhancement_level)
            analysis = analyze_text(text)
            
            results.append({
                'filename': file.name,
                'text': text,
                'analysis': analysis,
                'status': 'ì„±ê³µ',
                'timestamp': datetime.now().isoformat()
            })
        except Exception as e:
            results.append({
                'filename': file.name,
                'text': '',
                'analysis': {},
                'status': f'ì˜¤ë¥˜: {str(e)}',
                'timestamp': datetime.now().isoformat()
            })
        
        progress_bar.progress((i + 1) / len(uploaded_files))
    
    status_text.text("ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
    return results

# í…ìŠ¤íŠ¸ ë‚´ë³´ë‚´ê¸° í•¨ìˆ˜
def export_text_data(text, analysis, filename="extracted_text"):
    """í…ìŠ¤íŠ¸ ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
    try:
        # JSON í˜•íƒœë¡œ ë°ì´í„° êµ¬ì„±
        export_data = {
            'text': text,
            'analysis': analysis,
            'export_timestamp': datetime.now().isoformat(),
            'filename': filename
        }
        
        # JSON íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ
        json_str = json.dumps(export_data, ensure_ascii=False, indent=2)
        b64 = base64.b64encode(json_str.encode()).decode()
        href = f'<a href="data:file/json;base64,{b64}" download="{filename}_analysis.json" class="samsung-btn" style="display: inline-block; text-decoration: none; margin: 0.5rem;">ğŸ“Š JSON ë‚´ë³´ë‚´ê¸°</a>'
        
        # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ
        b64_text = base64.b64encode(text.encode('utf-8')).decode()
        href_text = f'<a href="data:file/txt;base64,{b64_text}" download="{filename}.txt" class="samsung-btn" style="display: inline-block; text-decoration: none; margin: 0.5rem;">ğŸ“„ í…ìŠ¤íŠ¸ ë‚´ë³´ë‚´ê¸°</a>'
        
        return href, href_text
    except Exception as e:
        st.error(f"ë‚´ë³´ë‚´ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
        return "", ""

# ë©”ì¸ ì•±
def main():
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.markdown("## ğŸ›ï¸ ì„¤ì •")
    
    # ê³ ê¸‰ ì˜µì…˜
    enhancement_level = st.sidebar.slider("ğŸ”§ ì´ë¯¸ì§€ í–¥ìƒ ë ˆë²¨", 1.0, 2.0, 1.2, 0.1)
    auto_analyze = st.sidebar.checkbox("ğŸ“Š ìë™ í…ìŠ¤íŠ¸ ë¶„ì„", value=True)
    auto_summarize = st.sidebar.checkbox("ğŸ¤– ìë™ AI ìš”ì•½", value=False)
    
    # AI ëª¨ë¸ ì„ íƒ
    selected_ai_model = st.sidebar.selectbox("ğŸ¤– AI ëª¨ë¸ ì„ íƒ", list(AI_MODELS.keys()))
    
    # í†µê³„ í‘œì‹œ
    st.sidebar.markdown("## ğŸ“Š í†µê³„")
    if 'total_processed' not in st.session_state:
        st.session_state.total_processed = 0
    if 'total_characters' not in st.session_state:
        st.session_state.total_characters = 0
    if 'processing_history' not in st.session_state:
        st.session_state.processing_history = []
    
    st.sidebar.metric("ì´ ì²˜ë¦¬ëœ ì´ë¯¸ì§€", st.session_state.total_processed)
    st.sidebar.metric("ì´ ì¶”ì¶œëœ ë¬¸ì", st.session_state.total_characters)
    
    # ë©”ì¸ íƒ­
    tabs = st.tabs(["ğŸ“± ë‹¨ì¼ ì´ë¯¸ì§€", "ğŸ“š ë°°ì¹˜ ì²˜ë¦¬", "ğŸ“Š ë¶„ì„ ëŒ€ì‹œë³´ë“œ", "ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„", "âš™ï¸ ì„¤ì •"])
    
    with tabs[0]:
        st.markdown('<div class="fade-in-up">', unsafe_allow_html=True)
        
        # ì´ë¯¸ì§€ ì—…ë¡œë“œ ì˜ì—­
        st.markdown('<div class="upload-area">', unsafe_allow_html=True)
        uploaded_image = st.file_uploader(
            "ğŸ“¥ ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=["jpg", "jpeg", "png", "bmp", "tiff", "webp", "jfif"],
            help="í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”"
        )
        st.markdown('</div>', unsafe_allow_html=True)
        
        # ì–¸ì–´ ì„ íƒ
        col1, col2 = st.columns(2)
        with col1:
            ocr_lang = st.selectbox("ğŸŒ ì¸ì‹í•  ì–¸ì–´ ì„ íƒ", list(LANG_CODE_MAP.keys()), index=0)
        with col2:
            if st.button("ğŸ” ì–¸ì–´ ìë™ ê°ì§€", use_container_width=True):
                st.info("ì–¸ì–´ ìë™ ê°ì§€ ê¸°ëŠ¥ì€ ì´ë¯¸ì§€ ì²˜ë¦¬ í›„ ë¶„ì„ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        if uploaded_image is not None:
            # ì´ë¯¸ì§€ í‘œì‹œ
            col1, col2 = st.columns([2, 1])
            with col1:
                st.image(uploaded_image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)
            
            with col2:
                # ì´ë¯¸ì§€ ì •ë³´
                img = Image.open(uploaded_image)
                st.markdown("### ğŸ“‹ ì´ë¯¸ì§€ ì •ë³´")
                st.write(f"**í¬ê¸°:** {img.size[0]} x {img.size[1]} px")
                st.write(f"**ëª¨ë“œ:** {img.mode}")
                st.write(f"**í˜•ì‹:** {img.format}")
                st.write(f"**íŒŒì¼ í¬ê¸°:** {uploaded_image.size / 1024:.1f} KB")
            
            lang_code = LANG_CODE_MAP[ocr_lang]
            
            # OCR ì²˜ë¦¬
            with st.spinner("ğŸ§  AI í…ìŠ¤íŠ¸ ì¸ì‹ ì¤‘..."):
                text = advanced_ocr_extraction(uploaded_image, lang_code, enhancement_level)
            
            if text.startswith("OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜"):
                st.markdown('<div class="error-message">', unsafe_allow_html=True)
                st.error(text)
                st.markdown('</div>', unsafe_allow_html=True)
            elif len(text.strip()) == 0:
                st.markdown('<div class="warning-message">', unsafe_allow_html=True)
                st.warning("â— ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
                st.markdown('</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="success-message">', unsafe_allow_html=True)
                st.success("âœ… í…ìŠ¤íŠ¸ ì¸ì‹ ì™„ë£Œ!")
                st.markdown('</div>', unsafe_allow_html=True)
                
                # í…ìŠ¤íŠ¸ ë¶„ì„
                if auto_analyze:
                    analysis = analyze_text(text)
                else:
                    analysis = {}
                
                # ê²°ê³¼ í‘œì‹œ
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.markdown('<div class="result-card">', unsafe_allow_html=True)
                    st.markdown("### ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
                    st.text_area("", value=text, height=300, key="extracted_text")
                    
                    # ë‚´ë³´ë‚´ê¸° ë²„íŠ¼
                    if analysis:
                        json_link, text_link = export_text_data(text, analysis, uploaded_image.name)
                        st.markdown(json_link, unsafe_allow_html=True)
                        st.markdown(text_link, unsafe_allow_html=True)
                    
                    st.markdown('</div>', unsafe_allow_html=True)
                
                with col2:
                    if analysis:
                        st.markdown("### ğŸ“Š í…ìŠ¤íŠ¸ ë¶„ì„")
                        st.metric("ë¬¸ì ìˆ˜", analysis.get('char_count', 0))
                        st.metric("ë‹¨ì–´ ìˆ˜", analysis.get('word_count', 0))
                        st.metric("ë¬¸ì¥ ìˆ˜", analysis.get('sentence_count', 0))
                        st.metric("ê°ì§€ëœ ì–¸ì–´", analysis.get('detected_language', 'N/A'))
                        st.metric("ë³µì¡ë„ ì ìˆ˜", f"{analysis.get('complexity_score', 0)}/100")
                        st.metric("ì½ê¸° ì‹œê°„", f"{analysis.get('reading_time_minutes', 0)}ë¶„")
                
                # AI ìš”ì•½
                if auto_summarize or st.button("ğŸ¤– AI ìš”ì•½ ìƒì„±", use_container_width=True, key="summarize_btn"):
                    with st.spinner(f"{selected_ai_model} ìš”ì•½ ì¤‘..."):
                        summary = ai_summarize_text(text, selected_ai_model)
                    
                    st.markdown('<div class="result-card">', unsafe_allow_html=True)
                    st.markdown("### ğŸ¤– AI ìš”ì•½ ê²°ê³¼")
                    st.text_area("", value=summary, height=200, key="summary_text")
                    st.markdown('</div>', unsafe_allow_html=True)
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                st.session_state.total_processed += 1
                st.session_state.total_characters += analysis.get('char_count', 0)
                
                # ì²˜ë¦¬ íˆìŠ¤í† ë¦¬ ì €ì¥
                history_entry = {
                    'timestamp': datetime.now().isoformat(),
                    'filename': uploaded_image.name,
                    'char_count': analysis.get('char_count', 0),
                    'word_count': analysis.get('word_count', 0),
                    'language': analysis.get('detected_language', 'N/A'),
                    'complexity_score': analysis.get('complexity_score', 0)
                }
                st.session_state.processing_history.append(history_entry)
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    with tabs[1]:
        st.markdown('<div class="fade-in-up">', unsafe_allow_html=True)
        st.markdown("## ğŸ“š ë°°ì¹˜ ì²˜ë¦¬")
        
        uploaded_files = st.file_uploader(
            "ğŸ“¥ ì—¬ëŸ¬ ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=["jpg", "jpeg", "png", "bmp", "tiff", "webp"],
            accept_multiple_files=True,
            help="ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
        
        batch_lang = st.selectbox("ğŸŒ ë°°ì¹˜ ì²˜ë¦¬ ì–¸ì–´ ì„ íƒ", list(LANG_CODE_MAP.keys()), index=0)
        
        if uploaded_files and st.button("ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘", use_container_width=True):
            batch_results = batch_process_images(uploaded_files, LANG_CODE_MAP[batch_lang], enhancement_level)
            
            # ê²°ê³¼ í‘œì‹œ
            st.markdown("### ğŸ“Š ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼")
            
            # ê²°ê³¼ í…Œì´ë¸”
            results_df = pd.DataFrame(batch_results)
            st.dataframe(results_df[['filename', 'status', 'timestamp']], use_container_width=True)
            
            # ìƒì„¸ ê²°ê³¼
            for result in batch_results:
                with st.expander(f"ğŸ“„ {result['filename']} - {result['status']}"):
                    if result['text']:
                        st.text_area("ì¶”ì¶œëœ í…ìŠ¤íŠ¸", value=result['text'], height=150, key=f"batch_{result['filename']}")
                        if result['analysis']:
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("ë¬¸ì ìˆ˜", result['analysis'].get('char_count', 0))
                            with col2:
                                st.metric("ë‹¨ì–´ ìˆ˜", result['analysis'].get('word_count', 0))
                            with col3:
                                st.metric("ê°ì§€ëœ ì–¸ì–´", result['analysis'].get('detected_language', 'N/A'))
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    with tabs[2]:
        st.markdown('<div class="fade-in-up">', unsafe_allow_html=True)
        st.markdown("## ğŸ“Š ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
        
        # ëŒ€ì‹œë³´ë“œ ë©”íŠ¸ë¦­
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.metric("ì´ ì²˜ë¦¬ëœ ì´ë¯¸ì§€", st.session_state.total_processed)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.metric("ì´ ì¶”ì¶œëœ ë¬¸ì", st.session_state.total_characters)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col3:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            avg_chars = st.session_state.total_characters / max(st.session_state.total_processed, 1)
            st.metric("í‰ê·  ë¬¸ì ìˆ˜", f"{avg_chars:.1f}")
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col4:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.metric("ì§€ì› ì–¸ì–´", len(LANG_CODE_MAP))
            st.markdown('</div>', unsafe_allow_html=True)
        
        # ìƒ˜í”Œ ë°ì´í„°ë¡œ ì°¨íŠ¸ ìƒì„±
        if 'extracted_text' in st.session_state and st.session_state.get('extracted_text'):
            analysis = analyze_text(st.session_state.extracted_text)
            fig1, fig2, fig3, fig4 = create_text_analysis_charts(analysis)
            
            if fig1 and fig2 and fig3 and fig4:
                col1, col2 = st.columns(2)
                with col1:
                    st.plotly_chart(fig1, use_container_width=True)
                with col2:
                    st.plotly_chart(fig2, use_container_width=True)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.plotly_chart(fig3, use_container_width=True)
                with col2:
                    st.plotly_chart(fig4, use_container_width=True)
        else:
            st.info("ğŸ“Š ë¶„ì„ ì°¨íŠ¸ë¥¼ ë³´ë ¤ë©´ ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    with tabs[3]:
        st.markdown('<div class="fade-in-up">', unsafe_allow_html=True)
        st.markdown("## ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„")
        
        if st.session_state.processing_history:
            # ì²˜ë¦¬ íˆìŠ¤í† ë¦¬ ì°¨íŠ¸
            history_df = pd.DataFrame(st.session_state.processing_history)
            
            # ì‹œê°„ë³„ ì²˜ë¦¬ëŸ‰
            fig_timeline = px.line(
                history_df,
                x='timestamp',
                y='char_count',
                title="ğŸ“ˆ ì‹œê°„ë³„ ì²˜ë¦¬ëœ ë¬¸ì ìˆ˜",
                labels={'char_count': 'ë¬¸ì ìˆ˜', 'timestamp': 'ì‹œê°„'}
            )
            fig_timeline.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font=dict(family="Inter", size=12)
            )
            st.plotly_chart(fig_timeline, use_container_width=True)
            
            # ì–¸ì–´ë³„ ë¶„í¬
            lang_counts = history_df['language'].value_counts()
            fig_lang = px.pie(
                values=lang_counts.values,
                names=lang_counts.index,
                title="ğŸŒ ì–¸ì–´ë³„ ì²˜ë¦¬ ë¶„í¬"
            )
            fig_lang.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font=dict(family="Inter", size=12)
            )
            st.plotly_chart(fig_lang, use_container_width=True)
            
            # ë³µì¡ë„ ì ìˆ˜ ë¶„í¬
            fig_complexity = px.histogram(
                history_df,
                x='complexity_score',
                title="ğŸ“Š í…ìŠ¤íŠ¸ ë³µì¡ë„ ì ìˆ˜ ë¶„í¬",
                nbins=10
            )
            fig_complexity.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font=dict(family="Inter", size=12)
            )
            st.plotly_chart(fig_complexity, use_container_width=True)
        else:
            st.info("ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„ì„ ë³´ë ¤ë©´ ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    with tabs[4]:
        st.markdown('<div class="fade-in-up">', unsafe_allow_html=True)
        st.markdown("## âš™ï¸ ê³ ê¸‰ ì„¤ì •")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### ğŸ”§ OCR ì„¤ì •")
            st.checkbox("ê³ ê¸‰ ì´ë¯¸ì§€ ì „ì²˜ë¦¬", value=True)
            st.checkbox("ìë™ ì–¸ì–´ ê°ì§€", value=False)
            st.checkbox("ì‹ ë¢°ë„ ì„ê³„ê°’ ì ìš©", value=True)
            
            st.markdown("### ğŸ¤– AI ì„¤ì •")
            st.selectbox("ê¸°ë³¸ AI ëª¨ë¸", list(AI_MODELS.keys()))
            st.slider("ìš”ì•½ ê¸¸ì´", 50, 500, 200)
        
        with col2:
            st.markdown("### ğŸ“Š ë¶„ì„ ì„¤ì •")
            st.checkbox("ìë™ í…ìŠ¤íŠ¸ ë¶„ì„", value=True)
            st.checkbox("í†µê³„ ì°¨íŠ¸ ìƒì„±", value=True)
            st.checkbox("ê²°ê³¼ ì €ì¥", value=False)
            
            st.markdown("### ğŸ¨ UI ì„¤ì •")
            st.selectbox("í…Œë§ˆ", ["Samsung Blue", "Dark", "Light"])
            st.checkbox("ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼", value=True)
        
        st.markdown("### ğŸ’¾ ë°ì´í„° ê´€ë¦¬")
        if st.button("ğŸ—‘ï¸ ëª¨ë“  ë°ì´í„° ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.clear()
            st.success("ëª¨ë“  ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # í‘¸í„°
    st.markdown("""
    <hr style="margin-top: 4rem;">
    <div style="text-align: center; color: #64748b; font-size: 0.9rem; padding: 2rem;">
        <p>ğŸ“± Samsung AI Text Recognition | Advanced OCR Technology</p>
        <p>Powered by Samsung AI & Machine Learning</p>
        <p style="font-size: 0.8rem; margin-top: 1rem;">Â© 2024 Samsung Electronics. All rights reserved.</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main() 